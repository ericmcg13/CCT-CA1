{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CA1 - Report.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericmcg13/CCT-CA1/blob/main/CA1_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJKbsoh_Dbk4"
      },
      "source": [
        "'Dash' is a required install for use of the plotly graphics and sliders.\n",
        "\n",
        "'ipyleaflet' is used for the geo mapping and Choropleth layer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MTZWOv0CLzv",
        "outputId": "bc4de1cf-f5ae-4333-bc93-4a0037191542"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/1AX4XfWghgqs3iUrzgCaaWPITgCfzP4IXKRXJ7r8zND24pF8jonGq7ZZfE8g\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG0Q4JTAOhHt"
      },
      "source": [
        "# New section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO1ZvbK6DHXp"
      },
      "source": [
        "# !pip install dash\n",
        "# !pip install ipyleaflet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWQIyMwUD0GC"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "\n",
        "# Set the plot to retina quality\n",
        "%config InlineBackend.figure_format = \"retina\"\n",
        "\n",
        "# Set the 'talk' library in SNS (Changes the size and labels to graphs to make them bigger)\n",
        "sns.set_context('talk')\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Multiple cell outputs\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_mode_interactivity = 'all'\n",
        "\n",
        "###\n",
        "\n",
        "# Below is only require for COLAB\n",
        "\n",
        "###\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGpGvbfXBW-v"
      },
      "source": [
        "migration_df = pd.read_csv(\"/content/drive/MyDrive/Migration.csv\")\n",
        "migration_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyGfTTO7iqPA"
      },
      "source": [
        "migration_df.shape\n",
        "migration_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eINEMoXB89ko"
      },
      "source": [
        "# Remove NaN values\n",
        "migration_df.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9pZMJ3cCNDi"
      },
      "source": [
        "migration_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmPOD3wm9B_z"
      },
      "source": [
        "# Group the totals by age cohort\n",
        "migration_sum_df = migration_df.groupby('Age Group').sum()\n",
        "\n",
        "# Remove the TOTAL column from the graph as it distorts the figures\n",
        "# migration_sum_df.drop(\"All ages\", axis=0, inplace=True)\n",
        "migration_sum_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6chl6eXwCF_5"
      },
      "source": [
        "# Filter the df by NET MIGRATION for ALL AGES and BOTH SEXES to get the totals\n",
        "net_migration = migration_df[(migration_df['Inward or Outward Flow'] == 'Net migration') & \n",
        "                             (migration_df['Age Group'] == 'All ages') &\n",
        "                             (migration_df['Sex'] == 'Both sexes')]\n",
        "net_migration.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwLD8P_SkR4M"
      },
      "source": [
        "# Show the inital graph to get a sense of the pattern (if any)\n",
        "fig = px.line(net_migration, x='Year', y='VALUE', color='Sex')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QiAJj_Jkes6"
      },
      "source": [
        "# Bring in the Birth/Death dataframe\n",
        "bdm_df = pd.read_csv('/content/drive/MyDrive/BDM_Ireland1960_2021.csv')\n",
        "bdm_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6O6waIQkeow"
      },
      "source": [
        "bdm_df.info()\n",
        "bdm_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PetcPMdHkemE"
      },
      "source": [
        "# Computer the net delta population growth (birth - death)\n",
        "bdm_df['Growth'] = bdm_df['Births Registered (Number)'] - bdm_df['Deaths Registered (Number)']\n",
        "\n",
        "# Use Lambda to iterate over the values in each cell to remove the QUARTER time values.\n",
        "bdm_df['Quarter'] = bdm_df['Quarter'].map(lambda x: str(x)[:-2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tb0XTH5kejB"
      },
      "source": [
        "bdm_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMWDOSFJkefW"
      },
      "source": [
        "# We only need the time and growth delta for graphing\n",
        "growth = bdm_df[['Quarter', 'Growth']].copy()\n",
        "growth = growth.groupby(['Quarter'], as_index=False)['Growth'].sum()\n",
        "\n",
        "# Quarter has been removed, only YEAR remains\n",
        "growth.columns = ['Year', 'Growth Delta']\n",
        "growth.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHvFbc6IkecM"
      },
      "source": [
        "# drop years less than 1987 for comparison with Growth\n",
        "compare_growth = growth[growth['Year'] > '1986']\n",
        "\n",
        "fig1 = px.line(compare_growth, x='Year', y='Growth Delta')\n",
        "fig1.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X6Tn6idkeS9"
      },
      "source": [
        "# We only need the Year and migration totals for graphing\n",
        "migration_df_simplified = net_migration[['Year', 'VALUE']].copy()\n",
        "\n",
        "# Convert STRING year in compare_growth to INT so that a JOIN can be performed\n",
        "compare_growth['Year'] = pd.to_numeric(compare_growth['Year'])\n",
        "\n",
        "# Join Columns\n",
        "merge_df = pd.merge(compare_growth, migration_df_simplified, how='outer', on='Year')\n",
        "\n",
        "# Fix VALUE column name and add\n",
        "merge_df.rename({'VALUE':'Migration Delta'}, axis=1, inplace=True)\n",
        "merge_df['Migration Delta'] = merge_df['Migration Delta'].apply(lambda x: int(x * 1000))\n",
        "merge_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wflH4WLak8H-"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Create figure with secondary y-axis\n",
        "fig2 = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "\n",
        "# Add trace - Growth\n",
        "fig2.add_trace(\n",
        "    go.Scatter(x=merge_df['Year'], y=merge_df['Growth Delta'], name=\"Growth\"),\n",
        "    secondary_y=False,\n",
        ")\n",
        "\n",
        "# Add trace - Migration\n",
        "fig2.add_trace(\n",
        "    go.Scatter(x=merge_df['Year'], y=merge_df['Migration Delta'], name=\"Migration\"),\n",
        "    secondary_y=False,\n",
        ")\n",
        "\n",
        "# Add figure title\n",
        "fig2.update_layout(\n",
        "    title_text=\"Pop Growth and Migration\"\n",
        ")\n",
        "\n",
        "# Set x-axis title\n",
        "fig2.update_xaxes(title_text=\"Year\")\n",
        "\n",
        "# Set y-axes titles\n",
        "fig2.update_yaxes(title_text=\"Population\", secondary_y=False)\n",
        "fig2.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j5fjOO7lBqR"
      },
      "source": [
        "# Import the employment data\n",
        "employment_df = pd.read_csv('/content/drive/MyDrive/Vacancies.csv')\n",
        "employment_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERkjg6uRlNBJ"
      },
      "source": [
        "employment_df.info()\n",
        "employment_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSjc50EylM9K"
      },
      "source": [
        "employment_df['Statistic'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiLCDdXGlMsQ"
      },
      "source": [
        "# We need the total number of vacancies for all sectors in all industries to get the totals\n",
        "employment_df = employment_df[(employment_df['Statistic'] == 'Number of Job Vacancies') &\n",
        "                             (employment_df['Private or Public Sector'] == 'All sectors') &\n",
        "                             (employment_df['Economic Sector NACE Rev 2'] == 'All NACE economic sectors')] \n",
        "\n",
        "employment_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lgU0R0mlUMf"
      },
      "source": [
        "# Use Lambda to iterate over the values in each cell and remove QUARTER time data\n",
        "employment_df['Quarter'] = employment_df['Quarter'].map(lambda x: str(x)[:-2])\n",
        "\n",
        "# We only need the year and total vacancies for graphing\n",
        "vacancies_df = employment_df[['Quarter', 'VALUE']].copy()\n",
        "vacancies_df = vacancies_df.groupby(['Quarter'], as_index=False)['VALUE'].sum()\n",
        "\n",
        "# Quarter has been removed, rename to year time frame\n",
        "vacancies_df.columns = ['Year', 'Open Vacancies']\n",
        "vacancies_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tdNYxNUlcxb"
      },
      "source": [
        "# Add the job vacancies data to the already created graph with the growth and pop data\n",
        "fig2.add_trace(\n",
        "    go.Scatter(x=vacancies_df['Year'], y=vacancies_df['Open Vacancies'], name=\"Open Vacancies\"),\n",
        "    secondary_y=False,\n",
        ")\n",
        "fig2.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om4-ZwmNlfgN"
      },
      "source": [
        "# Prepare the merge df to add the job vacancies data (only 2008 onwards is available in vacancies)\n",
        "merge_df = merge_df[merge_df['Year'] >= 2008]\n",
        "\n",
        "# Cast the Year columns as a Int for merge\n",
        "vacancies_df['Year'] = pd.to_numeric(vacancies_df['Year'])\n",
        "\n",
        "# Add the vacancies df with merge\n",
        "merge_df = pd.merge(merge_df, vacancies_df, how='outer', on='Year')\n",
        "merge_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY_UBbi6lj21"
      },
      "source": [
        "# Appears to be a corr. between migration and job vacancies - is this true?\n",
        "corrMatrix = merge_df.corr()\n",
        "sns.heatmap(corrMatrix, annot=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9-uIy2llmxT"
      },
      "source": [
        "# Heatmap shows that Migration numbers a moderately correlated to Open Job Vacancies\n",
        "# and that Population growth as a birth/death ratio has been on the decline since 2008\n",
        "# TODO: ML to show projections"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9sFgQnKCr6u"
      },
      "source": [
        "# Install the PROPHET dependancies for future series forcasting\n",
        "!pip install pystan\n",
        "!pip install fbprophet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egnJxTnIEH6o"
      },
      "source": [
        "from fbprophet import Prophet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi3vGYIvE-eW"
      },
      "source": [
        "# Documentation shows that the time series data must be in DATETIME format. I will convert that here.\n",
        "merge_df['Year'] = pd.to_datetime(merge_df['Year'], format='%Y')\n",
        "merge_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8sGz1lyHKuc"
      },
      "source": [
        "# The PROPHET documentation shows that the DF needs to only have 2 columns named ['ds' and 'y']\n",
        "prophet_df = merge_df.drop(['Migration Delta', 'Open Vacancies'], axis=1)\n",
        "prophet_df.columns = ['ds', 'y']\n",
        "prophet_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eayhduFsFshz"
      },
      "source": [
        "# train the model\n",
        "m = Prophet(interval_width=0.95)\n",
        "model = m.fit(prophet_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vV9ncbfPHERC"
      },
      "source": [
        "future = m.make_future_dataframe(periods=10, freq='Y')\n",
        "forcast = m.predict(future)\n",
        "forcast.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlFPEsmgIp0E"
      },
      "source": [
        "forcast.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikObmJUUJOr2"
      },
      "source": [
        "fig4 = m.plot(forcast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG-ea4G3MbZg"
      },
      "source": [
        "The forecasting chart above shows that if the population trend continues on its current trajectory, we could expect to see natural population growth to go negative, shortly after 2029. This means that Ireland is going to increasingly rely on immigration in order to support its economy. This will have a big effect on pension payments, tax collection, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmygIh5f59dm"
      },
      "source": [
        "births_df = pd.read_csv(\"/content/drive/MyDrive/BirthsByCounty1985_2020.csv\")\n",
        "births_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmU86-v26Ycw"
      },
      "source": [
        "births_df['County'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXFEyR0M-AKi"
      },
      "source": [
        "# This function will tidy up the county names based on the available values in the original file\n",
        "# It should remove all the duplication 'city' classifications and roll the \n",
        "def county_mapping(county):\n",
        "  if 'Dublin' in county or 'Fingal' in county or 'Laoghaire' in county:\n",
        "    return 'Dublin'\n",
        "  elif 'Cork' in county:\n",
        "    return 'Cork'\n",
        "  elif 'Galway' in county:\n",
        "    return 'Galway'\n",
        "  elif 'Limerick' in county:\n",
        "    return 'Limerick'\n",
        "  elif 'Tipperary' in county:\n",
        "    return 'Tipperary'\n",
        "  elif 'Waterford' in county:\n",
        "    return 'Waterford'\n",
        "  else:\n",
        "    return county"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdYTrc3P6dGF"
      },
      "source": [
        "# We need to clean up the COUNTY column to match values that are inline with the currenty county structure in Ireland\n",
        "# We can start by dropping the ROI totals\n",
        "births_df = births_df[births_df.County != 'ROI Total']\n",
        "\n",
        "# We can use lambda to go through each cell in COUNTY to map to the new county name\n",
        "births_df['Current_County'] = births_df['County'].apply(lambda x: county_mapping(str(x)))\n",
        "births_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY11LEHV_vF4"
      },
      "source": [
        "# Time to map map the county data\n",
        "from ipyleaflet import Map, Marker, basemaps, basemap_to_tiles"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}